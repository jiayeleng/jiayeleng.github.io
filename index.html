<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiaye's Homepage</title>

    <meta name="author" content="Jiaye Leng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="https://ok12static.oktacdn.com/bc/image/fileStoreRecord?id=fs0e7zb201YR74eyS5d7" type="image/x-icon"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jiaye Leng
                </p>
                <br>
                <h2><b>About</b></h2>
                <hr>
                <p>Hi, I'm Jiaye (冷佳业), a first-year Ph.D. student at <a href="https://www.cityu.edu.hk/">City University of Hong Kong (CityU)</a>, supervised by <a href="https://sweb.cityu.edu.hk/hongbofu/index.htm">Prof. Hongbo Fu</a>. Currently my research focuses on Human-AI Interaction and Computer Graphics, and I am also interested in VR/AR technology. I closely collaborated with <a href="https://huiye19.github.io/">Dr. Hui Ye</a>.
                </p>
                <p>
                  I graduated with a M.Eng. degree in Computer Technology from <a href="https://www.buaa.edu.cn/">Beihang University (BUAA)</a></a>, supervised by <a href="https://liliwang.net/">Prof. Lili Wang</a>, and received my B.Eng. degree in Electronic Information Science and Technology from <a href="https://www.cumt.edu.cn/">China University of Mining and Technology (CUMT)</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jiayeleng2-c@my.cityu.edu.hk">Email</a> &nbsp;/&nbsp;
                  <a href="data/LJY_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Ws3uaJEAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>
                </p>
              </td>
              <td style="padding:1.5%;width:20%;max-width:20%">
                <br>
                <a><img style="width:100%;max-width:100%;object-fit:cover;" alt="profile photo" src="images/ljy.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:-20px;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Publications</b></h2>
                <hr>
                <!--
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Representative papers are <span class="highlight">highlighted</span>.
                </p>
                -->
              </td>
            </tr>
          </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:-10px;"><tbody>
            
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/ProInterAR.jpg' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/10.1145/3613904.3642527">
          <span class="papertitle">ProInterAR: A Visual Programming Platform for Creating Immersive AR Interactions</span>
        </a>
        <br>
    <a href="https://huiye19.github.io/" style="text-decoration: underline; color: black;">Hui Ye*</a>,
    <strong>Jiaye Leng* (joint first author)</strong>,
    <a href="https://pengfeixu.com/" style="text-decoration: underline; color: black;">Pengfei Xu</a>,
    <a href="https://www.dgp.toronto.edu/~karan/" style="text-decoration: underline; color: black;">Karan Singh</a>,
    <a href="https://sweb.cityu.edu.hk/hongbofu/index.htm" style="text-decoration: underline; color: black;">Hongbo Fu</a>
        <br>
        <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems <b style="color: red;">(CHI 2024)</b></em>
        <br>
        <a href="paper/ProInterAR.pdf">[paper]</a>
        |
        <a href="https://www.youtube.com/watch?v=n7rIRIqmWqA">[video]</a>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/Flower Text Entry.jpg' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9874256">
          <span class="papertitle">Efficient Flower Text Entry in Virtual Reality</span>
        </a>
        <br>
    <strong>Jiaye Leng</strong>,
    <a href="https://liliwang.net/" style="text-decoration: underline; color: black;">Lili Wang</a>,
    Xiaolong Liu,
    Xuehuai Shi,
    <a href="http://miaowang.me/" style="text-decoration: underline; color: black;">Miao Wang</a>
        <br>
        <em>In IEEE Transactions on Visualization and Computer Graphics <b style="color: red;">(TVCG 2022)</b></em>
        <br>
        <a href="paper/Efficient_Flower_Text_Entry_in_Virtual_Reality.pdf">[paper]</a>
        |
        <a href="https://www.youtube.com/watch?v=HxamSluP4_w">[video]</a>
        <!--
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
          -->
      </td>
    </tr>

  </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:-20px;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <hr>
      </td>
    </tr>
  </tbody></table>
  
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/Light-Occlusion.jpeg' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://doi.org/10.1080/10447318.2023.2285646">
          <span class="papertitle">Light-Occlusion Text Entry in Mixed Reality</span>
        </a>
        <br>
    Aoxin Sun,
    <a href="https://liliwang.net/" style="text-decoration: underline; color: black;">Lili Wang</a>,
    <strong>Jiaye Leng</strong>,
    Sio Kei Im
        <br>
        <em>In International Journal of Human-Computer Interaction <b style="color: red;">(IJHCI 2023)</b></em>
        <br>
        <a href="paper/Light-Occlusion Text Entry in Mixed Reality.pdf">[paper]</a>
        |
        <a href="https://www.bilibili.com/video/BV1QK4y1B7LV/?vd_source=a17f0282b4b9fcc7f3e95becc47e4790">[video]</a>
        <!--
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
          -->
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/ProObjAR.jpeg' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://doi.org/10.1145/3544548.3580750">
          <span class="papertitle">ProObjAR: Prototyping Spatially-aware Interactions of Smart Objects with AR-HMD</span>
        </a>
        <br>
    <a href="https://huiye19.github.io/" style="text-decoration: underline; color: black;">Hui Ye</a>,
    <strong>Jiaye Leng</strong>,
    <a href="https://chufengxiao.github.io/" style="text-decoration: underline; color: black;">Chufeng Xiao</a>,
    <a href="https://liliwang.net/" style="text-decoration: underline; color: black;">Lili Wang</a>,
    <a href="https://sweb.cityu.edu.hk/hongbofu/index.htm" style="text-decoration: underline; color: black;">Hongbo Fu</a>
        <br>
        <em>In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems <b style="color: red;">(CHI 2023)</b></em>
        <br>
        <a href="paper/ProObjAR.pdf">[paper]</a>
        |
        <a href="https://www.youtube.com/watch?v=YnkOdbIkooc">[video]</a>
        <!--
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
          -->
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/Bidirectional.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9417794">
          <span class="papertitle">Bidirectional shadow rendering for interactive mixed 360° videos</span>
        </a>
        <br>
    <a href="https://liliwang.net/" style="text-decoration: underline; color: black;">Lili Wang</a>,
    Hao Wang,
    Danqing Dai,
    <strong>Jiaye Leng</strong>,
    <a href="https://gaplab.cuhk.edu.cn/pages/people" style="text-decoration: underline; color: black;">Xiaoguang Han</a>
        <br>
        <em>In 2021 IEEE Virtual Reality and 3D User Interfaces <b style="color: red;">(VR 2021)</b></em>
        <br>
        <a href="paper/Bidirectional_Shadow_Rendering_for_Interactive_Mixed_360_Videos.pdf">[paper]</a>
        |
        <a href="">[video]</a>
        <!--
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
          -->
      </td>
    </tr>

  </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">
            Website template from <a href="https://github.com/jonbarron/website">Jon Barron</a>
          </p>
        </td>
      </tr>
    </tbody></table>
    
        </td>
      </tr>
    </table>
  </body>
</html>
